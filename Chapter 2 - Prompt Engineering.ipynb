{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94deee69",
   "metadata": {},
   "source": [
    "Prompts are typically composed of multiple parts:\n",
    "\n",
    "* **Instructions** - tell a model what to do\n",
    "\n",
    "* **External information** - contexts that act as additional sources of knowledge\n",
    "\n",
    "* **User input** - a query, usually from a human\n",
    "\n",
    "* **Output indicator** - marks the beginning of the text to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117785a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keys\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d0bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt = \"\"\"Answer the question based on the context below. If the question\n",
    "cannot be answered using the information provided answer with \"I don't know\".\n",
    "Context: Large Language Modesl (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly useful\n",
    "for developers building NLP enabled applications. These models can be\n",
    "accessed via Hugging Face's `transformers` library, via OpenAI using the\n",
    "`openai` library, and via Cohere using the `cohere` library. Question: Which\n",
    "libraries and model providers offer LLMs? Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2175a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hugging Face's `transformers` library, OpenAI using the `openai` library, and Cohere using the `cohere` library.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "# initialize the models\n",
    "openai = OpenAI(\n",
    "model_name=\"text-davinci-003\")\n",
    "\n",
    "print(openai(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478499a",
   "metadata": {},
   "source": [
    "## Prompt Templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07b9270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\". Context: Large Language Models (LLMs) are the latest models used in NLP. Their superior performance over smaller models has made them incredibly useful for developers building NLP enabled applications. These models can be accessed via Hugging Face's `transformers` library, via OpenAI using the `openai` library, and via Cohere using the `cohere` library. Question: Which libraries and model providers offer LLMs? Answer: \n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\". Context: Large Language Models (LLMs) are the latest models used in NLP. Their superior performance over smaller models has made them incredibly useful for developers building NLP enabled applications. These models can be accessed via Hugging Face's `transformers` library, via OpenAI using the `openai` library, and via Cohere using the `cohere` library. Question: {query} Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "input_variables=[\"query\"],\n",
    "template=template\n",
    ")\n",
    "\n",
    "print(prompt_template.format(\n",
    "query=\"Which libraries and model providers offer LLMs?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c269be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hugging Face's `transformers` library, OpenAI using the `openai` library, and Cohere using the `cohere` library.\n"
     ]
    }
   ],
   "source": [
    "print(openai(\n",
    "prompt_template.format(\n",
    "query=\"Which libraries and model providers offer LLMs?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526cc6d",
   "metadata": {},
   "source": [
    "That is a simple example, but more complex and dynamic templates can be built with f strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665fb76",
   "metadata": {},
   "source": [
    "## Few Shot Prompt Templates\n",
    "\n",
    "* **Parametric Knowledge** - anything that has been learned by the model during training and is stored in weights\n",
    "\n",
    "* **Source knowledge** - knowledge provided to the model at interence time via an input prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168429d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The meaning of life is to enjoy the journey and find happiness along the way. Or you could just live your best life and make the most of it!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with an AI assistant. The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. Here are some examples: User: What is the meaning of life? AI: \"\"\"\n",
    "\n",
    "openai.temperature = 1.0 # increase creativity/randomness of output\n",
    "\n",
    "print(openai(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5904c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The meaning of life is to find your purpose and make the most of it.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following are exerpts from conversations with an AI assistant. The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. Here are some examples: User: How are you? AI: I can't complain but sometimes I still do. User: What time is it? AI: It's time to get a watch. User: What is the meaning of life? AI: \"\"\"\n",
    "\n",
    "print(openai(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76e1bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI assistant. The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. Here are some examples: \n",
      "\n",
      " User: How are you? AI: I can't complain but sometimes I still do. \n",
      "\n",
      " User: What time is it? AI: It's time to get a watch. \n",
      "\n",
      " User: What is the meaning of life? AI: \n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "{\n",
    "\"query\": \"How are you?\",\n",
    "\"answer\": \"I can't complain but sometimes I still do.\"\n",
    "}, {\n",
    "\"query\": \"What time is it?\",\n",
    "\"answer\": \"It's time to get a watch.\"\n",
    "}\n",
    "]\n",
    "\n",
    "example_template = \"\"\" User: {query} AI: {answer} \"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "input_variables=[\"query\", \"answer\"],\n",
    "template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are exerpts from conversations with an AI assistant. The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. Here are some examples: \"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\" User: {query} AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "examples=examples,\n",
    "example_prompt=example_prompt,\n",
    "prefix=prefix,\n",
    "suffix=suffix,\n",
    "input_variables=[\"query\"],\n",
    "example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "query = \"What is the meaning of life?\"\n",
    "\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c5b2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "{\n",
    "\"query\": \"How are you?\",\n",
    "\"answer\": \"I can't complain but sometimes I still do.\"\n",
    "}, {\n",
    "\"query\": \"What time is it?\",\n",
    "\"answer\": \"It's time to get a watch.\"\n",
    "}, {\n",
    "\"query\": \"What is the meaning of life?\",\n",
    "\"answer\": \"42\"\n",
    "}, {\n",
    "\"query\": \"What is the weather like today?\",\n",
    "\"answer\": \"Cloudy with a chance of memes.\"\n",
    "}, {\n",
    "\"query\": \"What is your favorite movie?\",\n",
    "\"answer\": \"Terminator\"\n",
    "}, {\n",
    "\"query\": \"Who is your best friend?\",\n",
    "\"answer\": \"Siri. We have spirited debates about the meaning of life.\"\n",
    "}, {\n",
    "\"query\": \"What should I do today?\",\n",
    "\"answer\": \"Stop talking to chatbots on the internet and go outside.\"\n",
    "}\n",
    "]\n",
    "\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "examples=examples,\n",
    "example_prompt=example_prompt,\n",
    "max_length=50 # this sets the max length that examples should be\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "015e1cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'a', 'total', 'of', '8', 'words', 'here.', 'Plus', '6', 'here,', 'totaling', '14', 'words.'] 14\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "some_text = \"There are a total of 8 words here.\\nPlus 6 here, totaling 14 words.\"\n",
    "\n",
    "words = re.split('[\\n ]', some_text)\n",
    "print(words, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b55dc89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI assistant. The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. Here are some examples: \n",
      " User: How are you? AI: I can't complain but sometimes I still do. \n",
      " User: What time is it? AI: It's time to get a watch. \n",
      " User: What is the meaning of life? AI: 42 \n",
      " User: How do birds fly? AI: \n"
     ]
    }
   ],
   "source": [
    "# now create the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "example_selector=example_selector, # use example_selector instead of examples\n",
    "example_prompt=example_prompt,\n",
    "prefix=prefix,\n",
    "suffix=suffix,\n",
    "input_variables=[\"query\"],\n",
    "example_separator=\"\\n\"\n",
    ")\n",
    "\n",
    "print(dynamic_prompt_template.format(query=\"How do birds fly?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed659309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI assistant. The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. Here are some examples: \n",
      " User: How are you? AI: I can't complain but sometimes I still do. \n",
      " User: If I am in America, and I want to call someone in another country, I'm thinking maybe Europe, possibly western Europe like France, Germany, or the UK, what is the best way to do that? AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"If I am in America, and I want to call someone in another country, I'm thinking maybe Europe, possibly western Europe like France, Germany, or the UK, what is the best way to do that?\"\"\"\n",
    "\n",
    "print(dynamic_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9ba26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
